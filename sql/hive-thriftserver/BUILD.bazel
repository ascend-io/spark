load("@rules_java//java:defs.bzl", "java_binary")

scala_library(
    name = "library",
    srcs = glob([
        "src/main/scala/**/*.scala",
        "src/main/java/**/*.java",
        "v2.3/src/main/scala/**/*.scala",
        "v2.3/src/main/java/**/*.java",
    ]),
    visibility = ["//visibility:public"],
    deps = [
        "//common/kvstore",
        "//common/tags",
        "//common/unsafe",
        "//core",
        "//sql/catalyst",
        "//sql/core",
        "//sql/hive",
        "@maven//:com_fasterxml_jackson_core_jackson_annotations",
        "@maven//:com_google_guava_guava",
        "@maven//:commons_cli_commons_cli",
        "@maven//:commons_codec_commons_codec",
        "@maven//:commons_io_commons_io",
        "@maven//:commons_logging_commons_logging",
        "@maven//:javax_servlet_javax_servlet_api",
        "@maven//:javax_ws_rs_javax_ws_rs_api",
        "@maven//:jline_jline",
        "@maven//:log4j_log4j",
        "@maven//:net_sf_jpam_jpam",
        "@maven//:org_apache_commons_commons_lang3",
        "@maven//:org_apache_commons_commons_text",
        "@maven//:org_apache_hadoop_hadoop_common",
        "@maven//:org_apache_hive_hive_cli",
        "@maven//:org_apache_hive_hive_common",
        "@maven//:org_apache_hive_hive_exec_core",
        "@maven//:org_apache_hive_hive_metastore",
        "@maven//:org_apache_hive_hive_serde",
        "@maven//:org_apache_hive_hive_service_rpc",
        "@maven//:org_apache_hive_hive_storage_api",
        "@maven//:org_apache_hive_shims_hive_shims_common",
        "@maven//:org_apache_httpcomponents_httpcore",
        "@maven//:org_apache_thrift_libthrift",
        "@maven//:org_eclipse_jetty_jetty_server",
        "@maven//:org_eclipse_jetty_jetty_servlet",
        "@maven//:org_eclipse_jetty_jetty_util",
        "@maven//:org_scala_lang_modules_scala_xml_2_12",
        "@maven//:org_slf4j_slf4j_api",
    ],
)

# to run: bazel build //sql/hive-thriftserver:hive-thriftserver && ./bazel-bin/sql/hive-thriftserver/hive-thriftserver --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 --name 'Thrift JDBC/ODBC Server' --master local spark-internal

# N.B.: at this point, a fat/deploy jar won't work for this: the datanucleus stuff has "plugin.xml" resources that all
# have the same name to if you create the typical fat jar that just does a merge, it fails to bootstrap

java_binary(
    name = "hive-thriftserver",
    jvm_flags = [
        "-Xmx1g",
    ],
    main_class = "org.apache.spark.deploy.SparkSubmit",
    runtime_deps = [
        ":library",
    ],
)
